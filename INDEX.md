# Bot Testing Framework - Complete Index

## ğŸ“‹ Start Here

New to this framework? **Read in this order:**

1. **[QUICK_START.md](QUICK_START.md)** âš¡ - 5 minutes
   - Installation
   - Run your first test
   - Basic troubleshooting

2. **[README.md](README.md)** ğŸ“– - 15 minutes
   - Architecture overview
   - What gets tested
   - How it works

3. **[IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md)** ğŸ—ï¸ - 20 minutes
   - What was built
   - Code examples
   - File structure

4. **[examples/README.md](examples/README.md)** ğŸ”§ - 10 minutes
   - 3 ways to run tests
   - Real output examples
   - Troubleshooting

5. **[examples/USAGE.md](examples/USAGE.md)** ğŸ“š - Reference
   - Detailed commands
   - Test coverage breakdown
   - Advanced usage

---

## ğŸš€ Quick Commands

### Install
```bash
cd AIforce_coding
pip install -r requirements.txt
```

### Recommended: Full Test Pipeline
```bash
cd AIforce_coding/tests
# Edit pipeline.py main() with your config path, then:
python3 pipeline.py
```

**What it runs**:
1. Config analysis and validation
2. Structural tests (24 tests)
3. Bot import on platform
4. Behavioral tests (33 tests)
5. Cleanup (removes bot)

### Alternative: Manual Pytest Control

**Structural Tests Only**:
```bash
cd AIforce_coding
pytest tests/test_structural.py --bot-config=/path/to/config.json -v
```

**Behavioral Tests Only** (requires deployed bot):
```bash
pytest tests/ -m behavioral \
  --bot-id=8553 \
  --current-version-id=8581 \
  --bot-config=/path/to/config.json -v
```

**Test All Bots** (structural only):
```bash
for bot in ../mws_api/test_api/bot-*.json; do
    pytest tests/test_structural.py --bot-config=$bot -v
done
```

---

## ğŸ“ File Structure

```
AIforce_coding/
â”‚
â”œâ”€â”€ ğŸ“„ Documentation (Start Here!)
â”‚   â”œâ”€â”€ INDEX.md                     â† You are here
â”‚   â”œâ”€â”€ QUICK_START.md               â† Read this first
â”‚   â”œâ”€â”€ README.md                    â† Full overview
â”‚   â””â”€â”€ IMPLEMENTATION_SUMMARY.md    â† Architecture details
â”‚
â”œâ”€â”€ ğŸ“¦ Framework Package (bot_testing/)
â”‚   â”œâ”€â”€ utils.py                     â† Utility functions (regex_to_sample)
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ loader.py                â† Load bot JSON
â”‚   â”‚   â”œâ”€â”€ extractor.py             â† Parse bot structure
â”‚   â”‚   â””â”€â”€ element_types.py         â† Data classes
â”‚   â”œâ”€â”€ execution/
â”‚   â”‚   â”œâ”€â”€ handler.py               â† Platform API handler
â”‚   â”‚   â””â”€â”€ client.py                â† Bot API client
â”‚   â””â”€â”€ coverage/
â”‚       â””â”€â”€ tracker.py               â† Coverage tracking (Phase 4)
â”‚
â”œâ”€â”€ ğŸ§ª Tests (tests/)
â”‚   â”œâ”€â”€ conftest.py                  â† Pytest fixtures + dynamic parametrization
â”‚   â”œâ”€â”€ test_structural.py           â† 24 structural tests
â”‚   â”œâ”€â”€ test_connectivity.py         â† 10 universal connectivity tests
â”‚   â”œâ”€â”€ test_entry_edges.py          â† 8 parametrized entry edge tests
â”‚   â””â”€â”€ test_blocks.py               â† 15 config-driven block tests
â”‚
â”œâ”€â”€ ğŸ”§ Examples (examples/)
â”‚   â”œâ”€â”€ README.md                    â† Examples guide
â”‚   â”œâ”€â”€ USAGE.md                     â† Detailed reference
â”‚   â”œâ”€â”€ run_bot_8553_tests.sh        â† Bash script
â”‚   â”œâ”€â”€ run_bot_8553_tests.py        â† Python script
â”‚   â””â”€â”€ run_tests_api.py             â† Programmatic API
â”‚
â”œâ”€â”€ âš™ï¸ Configuration
â”‚   â”œâ”€â”€ requirements.txt              â† Dependencies
â”‚   â”œâ”€â”€ pytest.ini                   â† Pytest config
â”‚   â””â”€â”€ .env.example                 â† Environment template
â”‚
â””â”€â”€ ğŸ“ Project Files
    â””â”€â”€ .gitignore                   â† Git exclusions
```

---

## ğŸ¯ What Each Component Does

### ConfigLoader (`bot_testing/config/loader.py`)
**Purpose**: Load bot configuration files
```python
loader = ConfigLoader("bot-8553.json")
config = loader.load()  # Returns dict
```

### ElementExtractor (`bot_testing/config/extractor.py`)
**Purpose**: Extract blocks, edges, nodes, scenarios
```python
extractor = ElementExtractor(config)
blocks = extractor.extract_blocks()
llm_blocks = extractor.extract_blocks_by_type("llm")
scenarios = extractor.extract_scenarios()
```

### Data Classes (`bot_testing/config/element_types.py`)
**Purpose**: Type-safe representation of bot elements
```python
BlockInfo, EntryEdgeInfo, NodeInfo, ScenarioInfo, BotInfo
```

### Test Fixtures (`tests/conftest.py`)
**Purpose**: Inject bot configuration into tests
```python
@pytest.fixture
def bot_config(bot_config_path):
    # Loads BOT_CONFIG_PATH environment variable
    return ConfigLoader(bot_config_path).load()
```

### Structural Tests (`tests/test_structural.py`)
**Purpose**: Validate bot configuration structure (24 tests)
```python
- TestBotConfiguration (3 tests)
- TestScenarioStructure (3 tests)
- TestNodeStructure (3 tests)
- TestBlockStructure (2 tests)
- TestEntryEdgeValidation (3 tests)
- TestNodeReferences (3 tests)
- TestRegexPatterns (1 test)
- TestVariableUsage (4 tests)
- TestScenarioConsistency (2 tests)
```

### BotTestClient (`bot_testing/execution/client.py`)
**Purpose**: API wrapper for behavioral tests (Phase 2)
```python
client = BotTestClient("http://api-url", "token")
await client.deploy_bot(config)
response = await client.send_message("hello")
```

### CoverageTracker (`bot_testing/coverage/tracker.py`)
**Purpose**: Track test coverage (Phase 4)
```python
tracker = CoverageTracker()
tracker.mark_block_tested("scenarios[0].nodes[0].blocks[0]")
summary = tracker.get_coverage_summary(total=50)
```

---

## ğŸ“Š Test Statistics

### Bot-8553 ("Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ‚Ğ¾Ñ€ ÑƒĞ¶Ğ¸Ğ½Ğ° v3")
- **Scenarios**: 6
- **Nodes**: ~15
- **Blocks**: ~31
  - Answer: 8
  - Buttons: 8
  - Extend: 7
  - LLM: 3
  - Single-If: 2
  - Wait: 3
- **Entry Edges**: 6 (5 match, 1 event)
- **Tests**: 24 structural tests
- **Time**: < 1 second

### Bot-97 ("supabase_check")
- **Scenarios**: 1
- **Nodes**: 2
- **Blocks**: ~5
- **Entry Edges**: 1
- **Tests**: 24 structural tests
- **Time**: < 1 second

---

## ğŸƒ Quickest Test Run

1. **Install**:
   ```bash
   cd AIforce_coding
   pip install -r requirements.txt
   ```

2. **Configure** (edit `tests/pipeline.py`):
   ```python
   config_path = "/path/to/your/bot-config.json"
   ```

3. **Run**:
   ```bash
   cd tests
   python3 pipeline.py
   ```

4. **See Results**:
   ```
   âœ“ Step 1: Config analyzed
   âœ“ Step 2: Structural tests PASSED (24 tests)
   âœ“ Step 3: Bot imported on platform
   âœ“ Step 4: Behavioral tests PASSED (33 tests)
   âœ“ Pipeline Completed Successfully!
   ```

---

## ğŸ” Full Test Pipeline with Analysis

The `pipeline.py` module provides comprehensive testing:

```bash
cd AIforce_coding/tests
python3 pipeline.py
```

**Pipeline Steps**:
1. **Config Analysis**
   - Validates JSON schema
   - Extracts bot elements (scenarios, nodes, blocks, edges)
   - Reports configuration summary
2. **Structural Tests**
   - 24 tests validating bot structure
   - No deployment required
3. **Platform Import**
   - Deploys bot via API
   - Returns bot_id and version_id
4. **Behavioral Tests**
   - 33 tests validating bot behavior
   - Config-driven and parametrized
   - Auto-skips tests for missing features
5. **Cleanup**
   - Removes bot from platform

---

## ğŸ› ï¸ For Developers

### Understanding the Framework

1. **Data Flow**:
   ```
   Bot JSON File
        â†“
   ConfigLoader.load()
        â†“
   {bot_config dict}
        â†“
   ElementExtractor(config)
        â†“
   BlockInfo, EntryEdgeInfo, NodeInfo...
        â†“
   Pytest Tests
   ```

2. **Test Injection**:
   ```
   BOT_CONFIG_PATH=bot-8553.json
        â†“
   conftest.py fixture
        â†“
   bot_config parameter
        â†“
   test_structural.py methods
   ```

3. **Generic Test Pattern**:
   ```python
   @pytest.mark.structural
   def test_validation(self, bot_config, element_extractor):
       # Same code, different bot!
       # Works for bot-97 AND bot-8553
       blocks = element_extractor.extract_blocks()
       assert len(blocks) > 0
   ```

### Adding New Tests

1. Open `tests/test_structural.py`
2. Find appropriate test class or create new one
3. Add test method with `@pytest.mark.structural`
4. Use fixtures: `bot_config`, `element_extractor`
5. Run: `BOT_CONFIG_PATH=../mws_api/test_api/bot-8553-v8581.json pytest tests/test_structural.py -v`

### Using in Your Code

```python
from bot_testing.config import ConfigLoader, ElementExtractor

# Load any bot
loader = ConfigLoader("my-bot.json")
config = loader.load()

# Extract elements
extractor = ElementExtractor(config)

# Work with elements
for block in extractor.extract_blocks():
    print(f"Block type: {block.type}")
    print(f"Scenario: {block.scenario_slug}")
    print(f"Configuration: {block.data}")
```

---

## ğŸ› Troubleshooting Quick Reference

| Problem | Solution |
|---------|----------|
| `pytest not found` | Run `pip install -r requirements.txt` |
| `Config file not found` | Set `BOT_CONFIG_PATH` or check path |
| `Module not found` | Run from `AIforce_coding` directory |
| `Permission denied` | Run `chmod +x examples/*.sh` |
| Test failures | Check output for which field is missing |

See `examples/USAGE.md` for detailed troubleshooting.

---

## ğŸ“ˆ What's Being Tested

### Configuration Level
- âœ“ Bot has required fields
- âœ“ Scenarios properly defined
- âœ“ Nodes properly defined
- âœ“ Blocks properly defined

### Reference Level
- âœ“ Button targets point to real nodes
- âœ“ Single-if targets point to real nodes
- âœ“ Extend blocks target real scenarios

### Type Level
- âœ“ Block types are valid
- âœ“ Edge types are valid

### Content Level
- âœ“ Regex patterns are valid
- âœ“ Variables are defined
- âœ“ LLM blocks have models
- âœ“ HTTP blocks have URLs
- âœ“ Button blocks have buttons

### Consistency Level
- âœ“ Node IDs are unique
- âœ“ Scenario IDs are unique
- âœ“ Scenario slugs are unique

---

## ğŸš¦ Status

### Phase 1: Structural Validation âœ… COMPLETE
- ConfigLoader, ElementExtractor
- 24 structural tests
- Works with bot-97 and bot-8553
- 3 executable examples

### Phase 2: Behavioral Tests âœ… COMPLETE
- Config-driven entry edge tests (parametrized over match edges)
- Universal connectivity tests (work for any bot)
- Block-type-specific tests with auto-skip
- 33 total behavioral tests across 3 files
- Config loads from file OR platform API

### Phase 3: Advanced Behavioral Tests ğŸ”œ UPCOMING
- Test LLM block execution with models
- Test HTTP request blocks
- Test Script block execution
- Coverage path tracking

### Phase 4: Coverage & Reporting ğŸ”œ UPCOMING
- HTML coverage reports
- CLI tool for easy test running
- CI/CD integration
- Coverage dashboard

---

## ğŸ“ Getting Help

1. **Quick answer?** â†’ Read [QUICK_START.md](QUICK_START.md)
2. **How it works?** â†’ Read [README.md](README.md)
3. **Code examples?** â†’ Read [IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md)
4. **Run examples?** â†’ See [examples/README.md](examples/README.md)
5. **Detailed reference?** â†’ See [examples/USAGE.md](examples/USAGE.md)
6. **Stuck?** â†’ Check [examples/USAGE.md](examples/USAGE.md) troubleshooting section

---

## ğŸ’¡ Key Insights

### 1. Generic Tests
Same test code works for **any bot** - no code generation needed!

### 2. Runtime Injection
Bot configuration is injected via environment variable - no test modifications needed!

### 3. Reusable Components
Framework components can be used independently in your code.

### 4. Extensible Design
Easy to add new tests or new block types without modifying existing code.

### 5. No Deployment Required
Structural tests run instantly without deploying to API.

---

## ğŸ“ Learn By Example

### Full Test Pipeline (Recommended)
```bash
cd AIforce_coding/tests
# Edit pipeline.py with your config path
python3 pipeline.py
```

### Programmatic Pipeline Access
```python
from tests.pipeline import run_full_pipeline

success = run_full_pipeline(
    config_path="/path/to/bot-config.json",
    skip_structural=False,   # Run structural tests
    skip_import=False,       # Import on platform
    skip_behavioral=False,   # Run behavioral tests
)
```

### Individual Pipeline Steps
```python
from tests.pipeline import (
    load_and_analyze_bot,
    run_pytest_structural,
    import_bot_on_platform,
    run_pytest_behavioral
)

# Step by step control
success, analyzer = load_and_analyze_bot(config_path)
run_pytest_structural(config_path)
bot_id, version_id = import_bot_on_platform(config_path)
run_pytest_behavioral(bot_id, version_id, config_path)
```

### Direct Pytest Control
```bash
cd AIforce_coding
pytest tests/test_structural.py --bot-config=/path/to/config.json -vv
pytest tests/ -m behavioral --bot-id=8553 --current-version-id=8581 --bot-config=/path/to/config.json -v
```

---

## âœ¨ Summary

You have a complete, working, extensible testing framework for bots!

**Current Status**: Phase 1 & 2 âœ…
- Structural validation tests (24 tests)
- Behavioral testing via API (33 tests)
- Full test pipeline orchestration
- Config-driven parametrization
- Auto-skip for missing features
- Comprehensive documentation

**Ready for**: Phase 3-4
- Advanced behavioral tests (LLM, HTTP, Script blocks)
- Coverage reporting and dashboards
- CI/CD integration

**Start testing**:
```bash
cd AIforce_coding/tests
# Edit pipeline.py with your config path
python3 pipeline.py
```

Enjoy! ğŸš€
